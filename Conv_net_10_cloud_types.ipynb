{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from skimage import io\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import Type, Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "from torchvision import transforms\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 16 16:59:47 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:82:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    36W / 250W |   8715MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разные режимы датасета \n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "# все изображения будут масштабированы к размеру 224x224 px\n",
    "RESCALE_SIZE = 224\n",
    "# работаем на видеокарте\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем датафрейм с путями и таргетами\n",
    "with open('df_10types.pkl', 'rb') as f:\n",
    "      df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем данные по дням.\n",
    "# В нашей задаче всего 240 дней.\n",
    "def train_test_split(df, test_size):\n",
    "    num_days = len(set(df['date_in_path'])) \n",
    "    ldays = list(set(df['date_in_path']))\n",
    "    days_per_size = int(num_days * test_size)\n",
    "    random.shuffle(ldays)\n",
    "    ltest = ldays[:days_per_size]\n",
    "    ltrain = ldays[days_per_size:]\n",
    "    return df[df['date_in_path'].isin(ltrain)], df[df['date_in_path'].isin(ltest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base 10 types:\n",
    "ctypes = ['ci', 'cc', 'cs', 'ac', 'as', 'sc', 'st', 'ns', 'cu', 'cb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Let there be 9 samples and 1 sample in class 0 and 1 respectively\n",
    "class_counts = list(df[ctypes].sum())\n",
    "num_samples = sum(class_counts)\n",
    "class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "labels_arr = df[ctypes].to_numpy(int)\n",
    "weights = list(list(map(lambda x, y: y if x == 1 else 0, labels, class_weights)) for labels in labels_arr)\n",
    "weights = torch.DoubleTensor(weights)\n",
    "train_sampler = WeightedRandomSampler(weights , len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и превращение в торчевые тензоры\n",
    "    \"\"\"\n",
    "    def __init__(self, df, mode):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = list(df['Full_path'])\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "        self.len_ = len(self.files)\n",
    "        self.labels = torch.FloatTensor(df[ctypes].values.astype(np.int))\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "                      \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "      \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "        transform = {\n",
    "            'val': transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "            ]),\n",
    "            'test': transforms.Compose([\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "            ]),\n",
    "            'train': transforms.Compose([\n",
    "                   transforms.ToPILImage(),\n",
    "                   transforms.ColorJitter(brightness=(0.5, 1.5), contrast=(0.5, 1.5), saturation=(0.5, 1.5)),                   \n",
    "                   transforms.RandomRotation(180),\n",
    "                   transforms.RandomResizedCrop(244),\n",
    "                   transforms.RandomHorizontalFlip(0.5),\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        }\n",
    "        x = self.load_sample(self.files[index])\n",
    "        x = self._prepare_sample(x)\n",
    "        if self.mode == 'test':\n",
    "            x = transform['test'](x)\n",
    "        elif self.mode == 'val':\n",
    "            x = transform['val'](x)\n",
    "        else:\n",
    "            x = transform['train'](x)\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "        \n",
    "    def _prepare_sample(self, image):\n",
    "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "        return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CloudDataset(train_df, mode='train')\n",
    "test_dataset = CloudDataset(test_df, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    \"\"\"Imshow для тензоров\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(20, 20), \\\n",
    "#                         sharey=True, sharex=True)\n",
    "# for fig_x in ax.flatten():\n",
    "#     random_pics = int(np.random.uniform(0,1000))\n",
    "#     im_val, label = train_dataset[random_pics]\n",
    "#     img_label = [ctypes[i] for i in range(10) if label[i] == 1]\n",
    "#     imshow(im_val.data.cpu(), title=img_label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ready_model(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet152(pretrained=True)\n",
    "        resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=resnet.fc.in_features, out_features=n_classes)\n",
    "        )\n",
    "        self.base_model = resnet\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigm(self.base_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_epoch(model: torch.nn.Module,\n",
    "                       optimizer: torch.optim.Optimizer,\n",
    "                       loss_function: torch.nn.Module,\n",
    "                       train_loader: torch.utils.data.DataLoader):\n",
    "    running_loss = 0.0\n",
    "    processed_size = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        processed_size += inputs.size(0)\n",
    "    train_loss = running_loss / processed_size\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_single_epoch(model: torch.nn.Module,\n",
    "                          loss_function: torch.nn.Module,\n",
    "                          val_loader: torch.utils.data.DataLoader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    processed_size = 0\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            metrics = calculate_metrics(np.array(outputs.cpu()), np.array(labels.cpu()))\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        processed_size += inputs.size(0)\n",
    "    val_loss = running_loss / processed_size\n",
    "    return {\"mean_loss\": val_loss, \"metrics\": metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use threshold to define predicted labels and invoke sklearn's metrics with different averaging strategies.\n",
    "def calculate_metrics(pred, target, threshold=0.5):\n",
    "    pred = np.array(pred > threshold, dtype=float)\n",
    "    return {'micro/f1': f1_score(y_true=target, y_pred=pred, average='micro', zero_division=0),\n",
    "            'macro/f1': f1_score(y_true=target, y_pred=pred, average='macro', zero_division=0),\n",
    "            'samples/f1': f1_score(y_true=target, y_pred=pred, average='samples', zero_division=0),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module,\n",
    "                train_dataset: torch.utils.data.Dataset,\n",
    "                val_dataset: torch.utils.data.Dataset,\n",
    "                loss_function: torch.nn.Module,\n",
    "                initial_lr: float,\n",
    "                optimizer_class: Type[torch.optim.Optimizer] = torch.optim,\n",
    "                optimizer_params: Dict = {\"momentum\": 0.975},\n",
    "                lr_scheduler_class: Any = torch.optim.lr_scheduler.ExponentialLR,\n",
    "                lr_scheduler_params: Dict = {\"gamma\": 0.1},\n",
    "                batch_size=16,\n",
    "                max_epochs=10,\n",
    "                early_stopping_patience=20):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=initial_lr, **optimizer_params)\n",
    "    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,shuffle=True, batch_size=batch_size, num_workers=8)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=8)\n",
    "\n",
    "    best_val_loss = None\n",
    "    best_epoch = None\n",
    "    \n",
    "    test_loss = []\n",
    "    train_loss = []\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        now = datetime.now()\n",
    "        train_epoch_loss = train_single_epoch(model, optimizer, loss_function, train_loader)\n",
    "        val_metrics = validate_single_epoch(model, loss_function, val_loader)\n",
    "        metrics = val_metrics['metrics']\n",
    "        test_epoch_loss = val_metrics['mean_loss']\n",
    "        test_loss.append(test_epoch_loss)\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        print(\"Epoch:{:2d}, time: {}, loss: {:.3f} \"\n",
    "              \"micro f1: {:.3f} \"\n",
    "              \"macro f1: {:.3f} \"\n",
    "              \"samples f1: {:.3f}\".format(epoch, datetime.now() - now, test_epoch_loss,\n",
    "                                          metrics['micro/f1'],\n",
    "                                          metrics['macro/f1'],\n",
    "                                          metrics['samples/f1']))\n",
    "        \n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        if best_val_loss is None or best_val_loss > val_metrics['mean_loss']:\n",
    "            print(f'Best model yet, saving')\n",
    "            best_val_loss = val_metrics['mean_loss']\n",
    "            best_epoch = epoch\n",
    "            torch.save({'state_dict': model.state_dict()}, 'best_model.pth.tar')\n",
    "\n",
    "        if epoch - best_epoch > early_stopping_patience:\n",
    "            print('Early stopping triggered')\n",
    "            return\n",
    "    return train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ready_model(len(ctypes))\n",
    "# Используем GPU\n",
    "model = model.cuda()\n",
    "\n",
    "train_loss, test_loss = train_model(model,\n",
    "                                    train_dataset=train_dataset,\n",
    "#                                     train_sampler=train_sampler,\n",
    "                                    val_dataset=test_dataset,  \n",
    "                                    loss_function=torch.nn.BCELoss(),\n",
    "                                    initial_lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_losses)), train_loss, label='train')\n",
    "plt.plot(range(len(test_losses)), test_loss, label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 эпох, resnet152:\n",
    "\n",
    "epoch: 0, loss: 0.309 micro f1: 1.000 macro f1: 0.100 samples f1: 1.000\n",
    "потом пополз вверх, скорее всего из за высокого lr\n",
    "\n",
    "Epoch: 2, time: 0:25:07.190805, loss: 0.313 micro f1: 0.857 macro f1: 0.096 samples f1: 0.846  loss=1e-4    explr g=0.1    медленно учится\n",
    "\n",
    "Epoch: 0, time: 0:28:47.170213, loss: 0.306 micro f1: 0.500 macro f1: 0.080 samples f1: 0.444 остановилась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "        for inputs, labels in test_loader:\n",
    "            print(inputs)\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[-2.0152, -2.0152, -1.9467,  ..., -2.0837, -2.0837, -2.0152],\n",
      "          [-1.9295, -2.0152, -1.9980,  ..., -2.0323, -2.0323, -2.0837],\n",
      "          [-1.9638, -2.0837, -1.9980,  ..., -2.0494, -2.0837, -2.1008],\n",
      "          ...,\n",
      "          [-2.0152, -1.9638, -2.0665,  ..., -2.0665, -2.0837, -1.9980],\n",
      "          [-2.1008, -2.0494, -2.0152,  ..., -1.9467, -2.0323, -2.1008],\n",
      "          [-1.9638, -2.0152, -1.9980,  ..., -1.9809, -2.0323, -2.1179]],\n",
      "\n",
      "         [[-1.8431, -1.8782, -1.8957,  ..., -1.8431, -1.8431, -1.8256],\n",
      "          [-1.8606, -1.8957, -1.8782,  ..., -1.9132, -1.9132, -1.7731],\n",
      "          [-1.8782, -1.8782, -1.8782,  ..., -1.9132, -1.9307, -1.7731],\n",
      "          ...,\n",
      "          [-1.8606, -1.8957, -1.8081,  ..., -1.8957, -1.9132, -1.8782],\n",
      "          [-1.7906, -1.8606, -1.8256,  ..., -1.9832, -1.9482, -1.8081],\n",
      "          [-1.9132, -1.9307, -1.8957,  ..., -1.9482, -1.9657, -1.7906]],\n",
      "\n",
      "         [[-1.6999, -1.6302, -1.7522,  ..., -1.7347, -1.7696, -1.6824],\n",
      "          [-1.7870, -1.7347, -1.7522,  ..., -1.7696, -1.7522, -1.7696],\n",
      "          [-1.8044, -1.7347, -1.7522,  ..., -1.7696, -1.6650, -1.7522],\n",
      "          ...,\n",
      "          [-1.7522, -1.7173, -1.7870,  ..., -1.7870, -1.7347, -1.6999],\n",
      "          [-1.7522, -1.6824, -1.7347,  ..., -1.7173, -1.6476, -1.7173],\n",
      "          [-1.7347, -1.6476, -1.7173,  ..., -1.7173, -1.6650, -1.8044]]],\n",
      "\n",
      "\n",
      "        [[[-1.9980, -1.9295, -1.9124,  ..., -2.0152, -2.0323, -2.0665],\n",
      "          [-2.0323, -1.9809, -1.9295,  ..., -1.9638, -1.9980, -1.9467],\n",
      "          [-1.9295, -1.9295, -1.9295,  ..., -1.9295, -1.9638, -1.9980],\n",
      "          ...,\n",
      "          [-1.8610, -1.8268, -1.8953,  ..., -1.9809, -1.9809, -1.8953],\n",
      "          [-1.8953, -1.9295, -1.8953,  ..., -1.9809, -1.9638, -2.0152],\n",
      "          [-1.9638, -1.8953, -1.8782,  ..., -1.9638, -1.9980, -2.0665]],\n",
      "\n",
      "         [[-1.8782, -1.9132, -1.8782,  ..., -1.7906, -1.8782, -1.8256],\n",
      "          [-1.8256, -1.8957, -1.8431,  ..., -1.8957, -1.9132, -1.8606],\n",
      "          [-1.8782, -1.8431, -1.8256,  ..., -1.8957, -1.8606, -1.7906],\n",
      "          ...,\n",
      "          [-1.7906, -1.8256, -1.7556,  ..., -1.7556, -1.8081, -1.7556],\n",
      "          [-1.8256, -1.8081, -1.7731,  ..., -1.7731, -1.7731, -1.7206],\n",
      "          [-1.7731, -1.8256, -1.7906,  ..., -1.8081, -1.7731, -1.7206]],\n",
      "\n",
      "         [[-1.6824, -1.6302, -1.7870,  ..., -1.7870, -1.7522, -1.6650],\n",
      "          [-1.7347, -1.6302, -1.7696,  ..., -1.7522, -1.7173, -1.6999],\n",
      "          [-1.7870, -1.8044, -1.7173,  ..., -1.7696, -1.7347, -1.7347],\n",
      "          ...,\n",
      "          [-1.5081, -1.5604, -1.6302,  ..., -1.5779, -1.4907, -1.6302],\n",
      "          [-1.5430, -1.5081, -1.5953,  ..., -1.5779, -1.6127, -1.7173],\n",
      "          [-1.6127, -1.5604, -1.5779,  ..., -1.5256, -1.6476, -1.6999]]],\n",
      "\n",
      "\n",
      "        [[[-1.9124, -1.8782, -1.9124,  ..., -2.1179, -1.9638, -1.8953],\n",
      "          [-1.9295, -1.9467, -1.9467,  ..., -2.0152, -1.9638, -1.9638],\n",
      "          [-1.9638, -1.9980, -1.9809,  ..., -2.0152, -2.0323, -2.0665],\n",
      "          ...,\n",
      "          [-1.8782, -1.9295, -2.0152,  ..., -2.0837, -1.9980, -1.9638],\n",
      "          [-1.9638, -1.9467, -1.9124,  ..., -2.1008, -1.9980, -1.9809],\n",
      "          [-1.8610, -1.8610, -1.8610,  ..., -2.0494, -2.0323, -1.9124]],\n",
      "\n",
      "         [[-1.7906, -1.9482, -1.9132,  ..., -1.8256, -1.8957, -1.8256],\n",
      "          [-1.8431, -1.9307, -1.8606,  ..., -1.8782, -1.8957, -1.7906],\n",
      "          [-1.8782, -1.8256, -1.8081,  ..., -1.9307, -1.8782, -1.7381],\n",
      "          ...,\n",
      "          [-1.8431, -1.8081, -1.8081,  ..., -1.8782, -1.8957, -1.8256],\n",
      "          [-1.8431, -1.8431, -1.8782,  ..., -1.7906, -1.8431, -1.8256],\n",
      "          [-1.8606, -1.8782, -1.8256,  ..., -1.7906, -1.8606, -1.8431]],\n",
      "\n",
      "         [[-1.7522, -1.5430, -1.5604,  ..., -1.6476, -1.6650, -1.7522],\n",
      "          [-1.6127, -1.4559, -1.5779,  ..., -1.6476, -1.5604, -1.6999],\n",
      "          [-1.4384, -1.5430, -1.6476,  ..., -1.6476, -1.6476, -1.6999],\n",
      "          ...,\n",
      "          [-1.6476, -1.6302, -1.7173,  ..., -1.5430, -1.6650, -1.7870],\n",
      "          [-1.5953, -1.6650, -1.6999,  ..., -1.6999, -1.7696, -1.7522],\n",
      "          [-1.6650, -1.7173, -1.7870,  ..., -1.7870, -1.7696, -1.7347]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.8782, -1.8439, -1.8782,  ..., -2.0152, -2.1008, -2.1008],\n",
      "          [-1.8953, -1.8610, -1.8439,  ..., -1.9809, -2.0665, -2.0837],\n",
      "          [-1.8439, -1.8610, -1.8953,  ..., -2.0837, -2.0494, -2.0323],\n",
      "          ...,\n",
      "          [-1.8097, -1.8097, -1.8782,  ..., -1.8610, -1.9124, -1.8439],\n",
      "          [-1.8953, -1.8610, -1.9124,  ..., -1.8439, -1.9124, -1.8268],\n",
      "          [-1.8439, -1.8953, -1.8953,  ..., -1.8782, -1.9809, -1.8953]],\n",
      "\n",
      "         [[-1.7031, -1.7031, -1.7031,  ..., -1.9132, -1.8256, -1.7906],\n",
      "          [-1.6856, -1.6856, -1.7206,  ..., -1.8957, -1.9307, -1.8256],\n",
      "          [-1.7381, -1.7206, -1.7031,  ..., -1.8782, -1.9482, -1.8957],\n",
      "          ...,\n",
      "          [-1.7031, -1.7031, -1.6856,  ..., -1.9482, -1.9482, -1.8957],\n",
      "          [-1.7206, -1.7031, -1.7031,  ..., -1.9307, -1.9132, -1.8782],\n",
      "          [-1.7381, -1.7206, -1.7031,  ..., -1.9132, -1.8957, -1.8782]],\n",
      "\n",
      "         [[-1.6824, -1.6302, -1.7347,  ..., -1.6824, -1.7696, -1.7696],\n",
      "          [-1.6476, -1.7173, -1.6476,  ..., -1.7522, -1.6650, -1.7696],\n",
      "          [-1.5604, -1.6650, -1.6650,  ..., -1.7173, -1.6999, -1.7522],\n",
      "          ...,\n",
      "          [-1.6999, -1.7173, -1.6824,  ..., -1.7347, -1.6650, -1.7347],\n",
      "          [-1.5953, -1.6127, -1.5604,  ..., -1.6476, -1.7522, -1.7347],\n",
      "          [-1.6127, -1.6476, -1.7696,  ..., -1.7696, -1.8044, -1.7696]]],\n",
      "\n",
      "\n",
      "        [[[-1.9467, -2.0323, -1.9295,  ..., -2.0665, -2.1008, -2.1179],\n",
      "          [-1.8953, -1.9980, -2.0152,  ..., -2.0837, -2.0837, -2.0665],\n",
      "          [-1.9295, -2.0323, -2.0494,  ..., -2.1179, -2.0494, -2.0323],\n",
      "          ...,\n",
      "          [-1.9809, -2.0494, -2.0323,  ..., -1.9638, -2.0665, -1.9295],\n",
      "          [-2.0665, -1.9980, -1.9809,  ..., -1.9980, -2.0323, -2.0494],\n",
      "          [-1.9980, -2.0323, -1.9638,  ..., -1.9124, -2.0494, -2.0323]],\n",
      "\n",
      "         [[-1.7731, -1.8256, -1.8431,  ..., -1.8957, -1.8782, -1.8256],\n",
      "          [-1.8081, -1.7731, -1.7731,  ..., -1.7906, -1.8081, -1.8431],\n",
      "          [-1.7906, -1.7556, -1.7556,  ..., -1.8256, -1.9132, -1.8606],\n",
      "          ...,\n",
      "          [-1.8081, -1.8431, -1.8081,  ..., -1.8606, -1.8081, -1.7906],\n",
      "          [-1.7556, -1.8081, -1.8081,  ..., -1.8081, -1.8431, -1.7906],\n",
      "          [-1.8431, -1.7556, -1.8081,  ..., -1.8431, -1.8431, -1.8081]],\n",
      "\n",
      "         [[-1.7347, -1.5779, -1.5430,  ..., -1.6127, -1.6650, -1.6824],\n",
      "          [-1.6476, -1.5953, -1.6999,  ..., -1.7696, -1.7522, -1.5953],\n",
      "          [-1.7173, -1.6476, -1.6824,  ..., -1.7522, -1.5953, -1.6302],\n",
      "          ...,\n",
      "          [-1.7173, -1.5256, -1.5779,  ..., -1.7173, -1.7522, -1.7870],\n",
      "          [-1.7347, -1.6824, -1.6650,  ..., -1.7522, -1.6999, -1.6127],\n",
      "          [-1.7522, -1.7696, -1.5953,  ..., -1.7870, -1.7173, -1.6302]]],\n",
      "\n",
      "\n",
      "        [[[-1.9638, -2.0494, -1.9809,  ..., -1.9638, -1.9809, -2.0665],\n",
      "          [-2.0494, -2.0323, -1.9467,  ..., -2.0665, -2.0837, -2.0665],\n",
      "          [-2.0152, -2.0152, -2.0152,  ..., -2.0152, -2.0494, -2.0837],\n",
      "          ...,\n",
      "          [-1.9638, -2.0152, -1.9980,  ..., -2.0837, -2.0152, -1.9809],\n",
      "          [-2.0152, -2.0152, -1.9980,  ..., -2.0494, -2.0665, -2.0152],\n",
      "          [-1.9809, -2.0494, -1.9809,  ..., -1.9809, -1.9809, -2.0665]],\n",
      "\n",
      "         [[-1.8782, -1.8081, -1.8606,  ..., -1.9307, -1.9132, -1.8081],\n",
      "          [-1.8431, -1.7906, -1.8606,  ..., -1.8431, -1.8606, -1.7906],\n",
      "          [-1.8957, -1.8606, -1.8782,  ..., -1.8431, -1.9307, -1.8081],\n",
      "          ...,\n",
      "          [-1.8431, -1.8782, -1.7906,  ..., -1.8606, -1.8431, -1.8256],\n",
      "          [-1.8606, -1.8256, -1.8256,  ..., -1.7906, -1.8606, -1.8606],\n",
      "          [-1.8957, -1.8081, -1.8782,  ..., -1.8606, -1.8782, -1.7906]],\n",
      "\n",
      "         [[-1.7870, -1.7696, -1.7173,  ..., -1.8044, -1.7696, -1.8044],\n",
      "          [-1.7870, -1.8044, -1.7347,  ..., -1.8044, -1.7696, -1.8044],\n",
      "          [-1.6999, -1.6824, -1.7173,  ..., -1.8044, -1.7347, -1.8044],\n",
      "          ...,\n",
      "          [-1.6127, -1.6650, -1.7522,  ..., -1.7173, -1.7522, -1.7696],\n",
      "          [-1.7522, -1.7522, -1.7173,  ..., -1.7347, -1.7173, -1.6824],\n",
      "          [-1.6302, -1.6650, -1.5256,  ..., -1.7347, -1.7347, -1.7696]]]]), tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1., 1., 0., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
      "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-1dd16c4e59c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-aaf460f3698a>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=8)\n",
    "probs = predict(model, val_loader)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# сохранить веса нашей нейросети model_C\n",
    "model_weights = copy.deepcopy(model.state_dict())\n",
    "torch.save(model_weights, \"model_wights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model_wights.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
    "probs = predict(model_ensemble, test_loader)\n",
    "\n",
    "\n",
    "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
    "test_filenames = [path.name for path in test_dataset.files]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
